{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4f7b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### RELATÓRIO RANDOM FOREST ###\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75       195\n",
      "           1       0.81      0.69      0.74       235\n",
      "           2       0.50      0.43      0.46         7\n",
      "\n",
      "    accuracy                           0.74       437\n",
      "   macro avg       0.67      0.64      0.65       437\n",
      "weighted avg       0.75      0.74      0.74       437\n",
      "\n",
      "\n",
      "### RELATÓRIO XGBOOST ###\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Em fase       0.76      0.78      0.77       195\n",
      "    Moderado       0.79      0.77      0.78       235\n",
      "      Severo       0.12      0.14      0.13         7\n",
      "\n",
      "    accuracy                           0.76       437\n",
      "   macro avg       0.56      0.56      0.56       437\n",
      "weighted avg       0.76      0.76      0.76       437\n",
      "\n",
      "\n",
      "### RELATÓRIO GRADIENT BOOSTING ###\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       195\n",
      "           1       0.77      0.76      0.77       235\n",
      "           2       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.75       437\n",
      "   macro avg       0.50      0.51      0.50       437\n",
      "weighted avg       0.74      0.75      0.74       437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Igor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Igor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\Igor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import joblib\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "\n",
    "df_dados = pd.read_csv(r\"C:\\Users\\Igor\\Documents\\GitHub\\DATATHON_2026\\DATATHON_2026\\data\\dados_processados\\BASE_DE_DADOS_PEDE_2024_DATATHON_LIMPO.csv\", sep=';')\n",
    "\n",
    "# #Variavel de risco\n",
    "def classificar_defasagem(x):\n",
    "    if x >= 0:\n",
    "        return 0   # Em fase\n",
    "    elif x >= -2:\n",
    "        return 1   # Moderado\n",
    "    else:\n",
    "        return 2   # Severo\n",
    "\n",
    "df_dados['Risco'] = df_dados['Defasagem'].apply(classificar_defasagem)\n",
    "\n",
    "\n",
    "\n",
    "features = ['IDA','IEG','IPS','IPP','IAA','IPV','Idade']\n",
    "X = df_dados[features]\n",
    "y = df_dados['Risco']\n",
    "\n",
    "\n",
    "# Treino e Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42,stratify=y \n",
    ")\n",
    "\n",
    "############################### modelo de classificação ###############################\n",
    "\n",
    "\n",
    "# Treinar modelo\n",
    "################################### RANDON ##############################################\n",
    "model_random = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',  \n",
    "    random_state=42,\n",
    "    n_jobs=-1             \n",
    ")\n",
    "model_random.fit(X_train, y_train)\n",
    "\n",
    "##################################### XGBOOST ########################################\n",
    "\n",
    "weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "model_xg = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=3,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "model_xg.fit(X_train, y_train, sample_weight=weights)\n",
    "\n",
    "######################################## GRADIENT #########################################\n",
    "\n",
    "model_gradient = GradientBoostingClassifier()\n",
    "model_gradient.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# --- Avaliação Random Forest ---\n",
    "pred_rf = model_random.predict(X_test)\n",
    "print(\"### RELATÓRIO RANDOM FOREST ###\")\n",
    "print(classification_report(y_test, pred_rf))\n",
    "\n",
    "# --- Avaliação XGBoost ---\n",
    "pred_xg = model_xg.predict(X_test)\n",
    "print(\"\\n### RELATÓRIO XGBOOST ###\")\n",
    "print(classification_report(\n",
    "    y_test, pred_xg,\n",
    "    target_names=[\"Em fase\", \"Moderado\", \"Severo\"]\n",
    "))\n",
    "\n",
    "# --- Avaliação Gradient Boosting ---\n",
    "pred_gb = model_gradient.predict(X_test)\n",
    "print(\"\\n### RELATÓRIO GRADIENT BOOSTING ###\")\n",
    "print(classification_report(y_test, pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a70c75b",
   "metadata": {},
   "source": [
    "### Optamos por utilizar o modelo Random Forest, pois apresentou um desempenho superior em comparação aos outros modelos testados, com uma melhor precisão e recall para a classe de risco. Além disso, o Random Forest é conhecido por sua robustez e capacidade de lidar com dados complexos, o que o torna uma escolha adequada para este tipo de problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9cba6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Igor\\\\Documents\\\\GitHub\\\\DATATHON_2026\\\\DATATHON_2026\\\\app\\\\modelo_risco_random.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################### Escolha do Modelo #################\n",
    "\n",
    "joblib.dump(model_random, r\"C:\\Users\\Igor\\Documents\\GitHub\\DATATHON_2026\\DATATHON_2026\\app\\modelo_risco_random.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (pyspark)",
   "language": "python",
   "name": "pyspark311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
